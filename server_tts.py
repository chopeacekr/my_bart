"""
Bark TTS Server v1.0.0

Suno AIì˜ Bark ëª¨ë¸ì„ ì‚¬ìš©í•œ í‘œí˜„ë ¥ ë†’ì€ ë‹¤êµ­ì–´ ìŒì„± í•©ì„± ì„œë²„
- 13ê°œ ì–¸ì–´ ì§€ì›
- 100ê°œ ì´ìƒì˜ í™”ì í”„ë¦¬ì…‹
- ë¹„ì–¸ì–´ì  í‘œí˜„ (ì›ƒìŒ, í•œìˆ¨, ìš¸ìŒ ë“±)
- ë°°ê²½ìŒì•… ë° íš¨ê³¼ìŒ ìƒì„± ê°€ëŠ¥
"""

import logging
import time
import io
import os
import warnings
from pathlib import Path
from typing import Optional

import torch
import torchaudio
from transformers import AutoProcessor, BarkModel
from fastapi import FastAPI, HTTPException, UploadFile, File, Form
from fastapi.responses import Response
from fastapi.middleware.cors import CORSMiddleware

# â­ Bark íŠ¹ìœ ì˜ ê²½ê³  ë©”ì‹œì§€ ì–µì œ
warnings.filterwarnings("ignore", message=".*attention mask.*")
warnings.filterwarnings("ignore", message=".*pad_token_id.*")
warnings.filterwarnings("ignore", message=".*pad token.*")

# transformers ë¡œê±° ê²½ê³  ì–µì œ
logging.getLogger("transformers.generation.utils").setLevel(logging.ERROR)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# FastAPI ì•± ìƒì„±
app = FastAPI(
    title="Bark TTS Server",
    description="Expressive multi-language speech synthesis with Bark",
    version="1.0.0"
)

# CORS ì„¤ì •
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì „ì—­ ë³€ìˆ˜
processor = None
model = None
device = None
sample_rate = 24000  # Barkì˜ ê¸°ë³¸ ìƒ˜í”Œë ˆì´íŠ¸


@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ëª¨ë¸ ë¡œë“œ"""
    global processor, model, device, sample_rate
    
    logger.info("")
    logger.info("â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—")
    logger.info("â•‘   Bark TTS Server                         â•‘")
    logger.info("â•‘   í¬íŠ¸: 8600                              â•‘")
    logger.info("â•‘   ëª¨ë¸: Bark Small (API v1.0.0)           â•‘")
    logger.info("â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•")
    logger.info("")
    logger.info("==================================================")
    logger.info("ğŸš€ Bark TTS Server ì‹œì‘ ì¤‘...")
    logger.info("==================================================")
    
    # ë””ë°”ì´ìŠ¤ ì„¤ì •
    if torch.cuda.is_available():
        device = torch.device("cuda")
        logger.info(f"ğŸ“± GPU ê°ì§€: {torch.cuda.get_device_name(0)}")
    else:
        device = torch.device("cpu")
        logger.info("ğŸ“± CPU ëª¨ë“œë¡œ ì‹¤í–‰")
    
    # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¶œë ¥
    import psutil
    process = psutil.Process()
    memory_info = process.memory_info()
    logger.info(f"ğŸ’¾ í˜„ì¬ ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰: {memory_info.rss / 1024 / 1024:.1f} MB")
    
    try:
        # Bark Small ëª¨ë¸ ë¡œë“œ
        logger.info("ğŸ“¦ Bark Small ëª¨ë¸ ë¡œë”© ì¤‘: suno/bark-small")
        logger.info("â³ ì²« ì‹¤í–‰ ì‹œ ëª¨ë¸ ë‹¤ìš´ë¡œë“œë¡œ 1-2ë¶„ ì†Œìš”ë  ìˆ˜ ìˆìŠµë‹ˆë‹¤...")
        
        processor = AutoProcessor.from_pretrained("suno/bark-small")
        model = BarkModel.from_pretrained("suno/bark-small")
        model = model.to(device)
        
        sample_rate = model.generation_config.sample_rate
        
        # ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ì¬í™•ì¸
        memory_info = process.memory_info()
        logger.info(f"ğŸ’¾ ëª¨ë¸ ë¡œë“œ í›„ ë©”ëª¨ë¦¬: {memory_info.rss / 1024 / 1024:.1f} MB")
        
        logger.info("==================================================")
        logger.info("âœ… Bark Small ëª¨ë¸ ë¡œë”© ì™„ë£Œ!")
        logger.info("ğŸ‰ Bark TTS Server ì¤€ë¹„ ì™„ë£Œ! (í¬íŠ¸: 8600)")
        logger.info("==================================================")
        
    except Exception as e:
        logger.error(f"âŒ ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {e}")
        raise


@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "service": "Bark TTS Server",
        "version": "1.0.0",
        "model": "suno/bark-small",
        "status": "running",
        "features": [
            "Multi-language support (13 languages)",
            "100+ speaker presets",
            "Non-verbal expressions ([laughs], [sighs], etc.)",
            "Music and sound effects generation",
        ]
    }


@app.get("/health")
async def health_check():
    """í—¬ìŠ¤ ì²´í¬"""
    return {
        "status": "ok",
        "model_loaded": model is not None,
        "device": str(device),
        "sample_rate": sample_rate,
    }


@app.post("/synthesize")
async def synthesize_speech(
    text: str = Form(...),
    voice_preset: Optional[str] = Form(None),
    speed: float = Form(1.0),
):
    """
    í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
    
    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸ (íŠ¹ìˆ˜ í† í° ì‚¬ìš© ê°€ëŠ¥: [laughs], [sighs], [music], etc.)
        voice_preset: í™”ì í”„ë¦¬ì…‹ (ì˜ˆ: v2/en_speaker_0, v2/ko_speaker_1)
        speed: ìŒì„± ì†ë„ (0.5 ~ 2.0, ê¸°ë³¸ê°’: 1.0)
    
    Returns:
        WAV ì˜¤ë””ì˜¤ íŒŒì¼
    """
    if model is None:
        raise HTTPException(status_code=503, detail="Model not loaded")
    
    start_time = time.time()
    temp_files = []
    
    try:
        logger.info(f"ğŸ“ TTS ìš”ì²­: '{text[:50]}...' (ê¸¸ì´: {len(text)})")
        
        if voice_preset:
            logger.info(f"ğŸ­ í™”ì í”„ë¦¬ì…‹: {voice_preset}")
        else:
            logger.info("â„¹ï¸  ê¸°ë³¸ í™”ì í”„ë¦¬ì…‹ ì‚¬ìš©")
        
        logger.info(f"âš¡ ì†ë„: {speed}x")
        
        # í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
        inputs = processor(text, return_tensors="pt", voice_preset=voice_preset).to(device)
        
        # TTS ìƒì„±
        logger.info("ğŸ¤ ìŒì„± ìƒì„± ì¤‘...")
        
        with torch.inference_mode():
            audio_array = model.generate(**inputs)
        
        # NumPy ë°°ì—´ë¡œ ë³€í™˜ ë° ì°¨ì› ì¡°ì •
        audio_array = audio_array.cpu().numpy().squeeze()
        
        # ì†ë„ ì¡°ì ˆ
        if speed != 1.0:
            import scipy.signal as signal
            audio_array = signal.resample(
                audio_array,
                int(len(audio_array) / speed)
            )
        
        # ì˜¤ë””ì˜¤ ì •ê·œí™” (int16 ë²”ìœ„ë¡œ)
        audio_array = audio_array / max(abs(audio_array.max()), abs(audio_array.min()))
        audio_int16 = (audio_array * 32767).astype('int16')
        
        # ì„ì‹œ íŒŒì¼ì— WAV ì €ì¥ (scipy ì‚¬ìš©)
        import scipy.io.wavfile as wavfile
        temp_wav_path = f"/tmp/bark_output_{int(time.time())}.wav"
        temp_files.append(temp_wav_path)
        
        wavfile.write(temp_wav_path, sample_rate, audio_int16)
        
        # ì„ì‹œ íŒŒì¼ì„ ë©”ëª¨ë¦¬ë¡œ ì½ê¸°
        with open(temp_wav_path, "rb") as f:
            audio_bytes = f.read()
        
        elapsed_time = time.time() - start_time
        audio_size = len(audio_bytes)
        
        logger.info(f"âœ… TTS ë³€í™˜ ì™„ë£Œ")
        logger.info(f"   - ì²˜ë¦¬ ì‹œê°„: {elapsed_time:.2f}ì´ˆ")
        logger.info(f"   - ìƒ˜í”Œë ˆì´íŠ¸: {sample_rate}Hz")
        logger.info(f"   - ì˜¤ë””ì˜¤ í¬ê¸°: {audio_size / 1024:.1f} KB")
        
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for temp_file in temp_files:
            if os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                    logger.debug(f"ğŸ—‘ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œ: {temp_file}")
                except Exception as cleanup_error:
                    logger.warning(f"âš ï¸  ì„ì‹œ íŒŒì¼ ì‚­ì œ ì‹¤íŒ¨: {temp_file} - {cleanup_error}")
        
        # WAV íŒŒì¼ ë°˜í™˜
        return Response(
            content=audio_bytes,
            media_type="audio/wav",
            headers={
                "X-Processing-Time": str(round(elapsed_time, 2)),
                "X-Sample-Rate": str(sample_rate),
                "X-Device": str(device),
            }
        )
        
    except Exception as e:
        logger.error(f"âŒ TTS ë³€í™˜ ì‹¤íŒ¨: {e}")
        logger.error(f"Traceback (most recent call last):")
        import traceback
        logger.error(traceback.format_exc())
        
        # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ì„ì‹œ íŒŒì¼ ì •ë¦¬
        for temp_file in temp_files:
            if os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except:
                    pass
        
        raise HTTPException(status_code=500, detail=str(e))


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "server_tts:app",
        host="0.0.0.0",
        port=8600,
        reload=False
    )